package c0x12c.ai.docsummarizer

import c0x12c.ai.chat.ChatMetadata
import c0x12c.ai.chat.ChatService
import c0x12c.ai.model.Message
import c0x12c.ai.model.MessageRole
import c0x12c.ai.monitoring.CallTypeTag
import c0x12c.ai.monitoring.OutputTypeTag
import c0x12c.ai.monitoring.BusinessFunctionTag
import c0x12c.ai.docsummarizer.model.DocumentationType
import c0x12c.logging.logger

class MapReduceDocumentSummarizer(
  private val chatService: ChatService
) : DocumentSummarizer {

  companion object {
    private val logger = MapReduceDocumentSummarizer::class.logger()
    private const val COMPLETION_TOKEN_BUFFER_RATIO = 0.2 // 20% of context window for completion buffer
    private const val MIN_COMPLETION_BUFFER = 1_024
  }

  override suspend fun summarize(
    document: String,
    docType: DocumentationType,
    metadata: ChatMetadata
  ): String {
    val contextWindow = chatService.contextWindowSize
    val completionTokenBuffer = (contextWindow * COMPLETION_TOKEN_BUFFER_RATIO).toInt().coerceAtLeast(MIN_COMPLETION_BUFFER)
    val adjustedContextWindow = contextWindow - completionTokenBuffer
    val systemPrompt = docType.systemPrompt
    val promptTemplate = docType.promptTemplate
    val totalTokenCount = calculateTotalTokenCount(systemPrompt, promptTemplate, document)

    logger.info("Starting summarization for document with total $totalTokenCount tokens (context window: $contextWindow, adjusted: $adjustedContextWindow, buffer: $completionTokenBuffer)")
    if (totalTokenCount <= adjustedContextWindow) {
      return summarizeContent(document, docType, chatService, metadata)
    }

    val chunks = docType.chunkDocument(document, contextWindow, chatService.tokenizer, systemPrompt, promptTemplate)

    val initialSummaries = chunks.mapIndexed { index, chunk ->
      val chunkTotalTokenCount = calculateTotalTokenCount(systemPrompt, promptTemplate, chunk)
      if (chunkTotalTokenCount <= adjustedContextWindow) {
        summarizeContent(chunk, docType, chatService, metadata)
      } else {
        summarize(chunk, docType, metadata) // Recursive call
      }
    }

    val finalSummary = reduceSummaries(initialSummaries, docType, chatService, metadata)
    logger.info("Summarization completed, final summary length: ${finalSummary.length}")
    return finalSummary
  }

  private suspend fun reduceSummaries(
    summaries: List<String>,
    docType: DocumentationType,
    chatService: ChatService,
    metadata: ChatMetadata
  ): String {
    val contextWindow = chatService.contextWindowSize
    val completionTokenBuffer = (contextWindow * COMPLETION_TOKEN_BUFFER_RATIO).toInt().coerceAtLeast(MIN_COMPLETION_BUFFER)
    val adjustedContextWindow = contextWindow - completionTokenBuffer
    val systemPrompt = docType.systemPrompt
    val promptTemplate = docType.promptTemplate
    var currentSummaries = summaries

    while (currentSummaries.size > 1) {
      val batches = createBatches(currentSummaries, adjustedContextWindow, systemPrompt, promptTemplate)

      currentSummaries = batches.mapIndexed { index, batch ->
        val concatenated = batch.joinToString("\n\n")
        val concatenatedTokenCount = calculateTotalTokenCount(systemPrompt, promptTemplate, concatenated)
        if (concatenatedTokenCount <= adjustedContextWindow) {
          summarizeContent(concatenated, docType, chatService, metadata)
        } else {
          logger.debug("Batch $index too large ($concatenatedTokenCount > $adjustedContextWindow), summarizing recursively")
          summarize(concatenated, docType, metadata)
        }
      }
    }

    return currentSummaries.first()
  }

  private suspend fun summarizeContent(
    content: String,
    docType: DocumentationType,
    chatService: ChatService,
    metadata: ChatMetadata
  ): String {
    val systemPrompt = docType.systemPrompt
    val userMessage = docType.formatPrompt("content" to content)
    val summarizeSystemMessage = Message(systemPrompt, MessageRole.SYSTEM)
    val summarizeUserMessage = Message(userMessage, MessageRole.USER)
    val response = chatService.chatAsync(
      messages = listOf(summarizeSystemMessage, summarizeUserMessage),
      tools = null,
      useJsonResponseFormat = false,
      monitoringTags = listOf(
        CallTypeTag.ASYNC.toString(),
        OutputTypeTag.TEXT.toString(),
        BusinessFunctionTag.SUMMARIZE_CONTENT.toString()
      ),
      metadata = metadata
    )
    return response.text()
  }

  private fun createBatches(
    summaries: List<String>,
    contextWindow: Int,
    systemPrompt: String,
    promptTemplate: String
  ): List<List<String>> {
    val batches = mutableListOf<List<String>>()
    var currentBatch = mutableListOf<String>()
    val baseTokenCount = calculateBaseTokenCount(systemPrompt, promptTemplate)
    var currentTokenCount = baseTokenCount

    for (summary in summaries) {
      val summaryTokenCount = chatService.countToken(summary)
      val estimatedTokenCount = currentTokenCount + summaryTokenCount + 2 // 2 for "\n\n"

      if (estimatedTokenCount > contextWindow && currentBatch.isNotEmpty()) {
        batches.add(currentBatch.toList())
        currentBatch = mutableListOf()
        currentTokenCount = baseTokenCount
      }

      currentBatch.add(summary)
      currentTokenCount += summaryTokenCount + 2
    }

    if (currentBatch.isNotEmpty()) {
      batches.add(currentBatch.toList())
    }

    return batches
  }

  private fun calculateTotalTokenCount(
    systemPrompt: String,
    promptTemplate: String,
    content: String
  ): Int {
    val baseTokens = calculateBaseTokenCount(systemPrompt, promptTemplate)
    val contentTokens = chatService.countToken(content)
    return baseTokens + contentTokens
  }

  private fun calculateBaseTokenCount(
    systemPrompt: String,
    promptTemplate: String
  ): Int {
    return chatService.countToken(systemPrompt) + chatService.countToken(promptTemplate)
  }
}
